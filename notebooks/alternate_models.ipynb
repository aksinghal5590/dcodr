{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_df, test_df, cell_features):\n",
    "\n",
    "    train_Y = np.array(train_df['auc'])\n",
    "    test_Y = np.array(test_df['auc'])\n",
    "\n",
    "    train_X = np.empty(shape = (len(train_df), len(cell_features[0, :])))\n",
    "    test_X = np.empty(shape = (len(test_df), len(cell_features[0, :])))\n",
    "\n",
    "    for i, row in train_df.iterrows():\n",
    "        train_X[i] = cell_features[int(cell_map[row['cell']])]\n",
    "\n",
    "    for i, row in test_df.iterrows():\n",
    "        test_X[i] = cell_features[int(cell_map[row['cell']])]\n",
    "        \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_feat(df, gene_list, cell_map, cell_features):\n",
    "\n",
    "    Y = np.array(df['auc'])\n",
    "\n",
    "    X = np.empty(shape = (len(df), len(cell_features[0, :])))\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        X[i] = cell_features[int(cell_map[row['cell']])]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_data(all_df):\n",
    "    \n",
    "    train_cell_lines = list(set(all_df['cell']))\n",
    "    val_cell_lines = []\n",
    "    val_size = int(len(train_cell_lines)/5)\n",
    "    \n",
    "    for _ in range(val_size):\n",
    "        r = rd.randint(0, len(train_cell_lines) - 1)\n",
    "        val_cell_lines.append(train_cell_lines.pop(r))\n",
    "        \n",
    "    val_df = all_df.query('cell in @val_cell_lines').reset_index(drop=True)\n",
    "    train_df = all_df.query('cell in @train_cell_lines').reset_index(drop=True)\n",
    "    \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_elasticnet(trial, train_df, val_df, cell_features):\n",
    "    \n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.01, 1.0, log=True)\n",
    "    alpha = trial.suggest_float('alpha', 0.01, 1.0, log=True)\n",
    "\n",
    "    train_X, train_Y, val_X, val_Y = prepare_data(train_df, val_df, cell_features)\n",
    "    \n",
    "    regr = ElasticNet(fit_intercept=False, max_iter=3000, tol=1e-3, l1_ratio=l1_ratio, alpha=alpha)\n",
    "    regr.fit(train_X, train_Y)\n",
    "    predicted_Y = regr.predict(val_X)\n",
    "    corr = stats.pearsonr(val_Y, predicted_Y)[0]\n",
    "    if math.isnan(corr):\n",
    "        corr = 0.0\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_elastic_net(dataset, ont, drug, cell_features, folds=5):\n",
    "    \n",
    "    fold_corr_list = []\n",
    "    corr_sum = 0.0\n",
    "    for i in range(1, folds+1):\n",
    "\n",
    "        all_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_train_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=(['cell', 'smiles', 'auc', 'dataset']))\n",
    "        train_df, val_df = split_train_data(all_df)\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(lambda trial: optimize_elasticnet(trial, train_df, val_df, cell_features), n_trials=50)\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        test_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_test_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=['cell', 'smiles', 'auc', 'dataset'])\n",
    "        train_X, train_Y, test_X, test_Y = prepare_data(all_df, test_df, cell_features)\n",
    "        \n",
    "        regr = ElasticNet(fit_intercept=False, max_iter=3000, tol=1e-3, l1_ratio=best_params['l1_ratio'], alpha=best_params['alpha'])\n",
    "        regr.fit(train_X, train_Y)\n",
    "        predicted_Y = regr.predict(test_X)\n",
    "\n",
    "        corr = stats.pearsonr(test_Y, predicted_Y)[0]\n",
    "        if math.isnan(corr):\n",
    "            corr = 0.0\n",
    "        fold_corr_list.append(corr)\n",
    "        corr_sum += corr\n",
    "\n",
    "        modeldir = \"../models/elastic_net/\"\n",
    "        np.savetxt(modeldir + \"predict_\" + dataset + '_' + drug + '_' + str(i) + \".txt\", predicted_Y, fmt = '%.4e')\n",
    "\n",
    "    return fold_corr_list, (corr_sum/folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(dataset, ont, drug, cell_features, folds=5):\n",
    "    \n",
    "    fold_corr_list = []\n",
    "    corr_sum = 0.0\n",
    "    for i in range(1, folds+1):\n",
    "\n",
    "        train_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_train_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=(['cell', 'smiles', 'auc', 'dataset']))\n",
    "        test_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_test_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=['cell', 'smiles', 'auc', 'dataset'])\n",
    "        train_X, train_Y, test_X, test_Y = prepare_data(train_df, test_df, cell_features)\n",
    "        \n",
    "        regr = RandomForestRegressor(random_state=0, n_jobs=-2)\n",
    "        regr.fit(train_X, train_Y)\n",
    "        predicted_Y = regr.predict(test_X)\n",
    "    \n",
    "        corr = stats.pearsonr(test_Y, predicted_Y)[0]\n",
    "        fold_corr_list.append(corr)\n",
    "        corr_sum += corr\n",
    "\n",
    "        modeldir = \"../models/random_forest/\"\n",
    "        np.savetxt(modeldir + \"predict_\" + dataset + '_' + drug + '_' + str(i) + \".txt\", predicted_Y, fmt = '%.4e')\n",
    "\n",
    "    return fold_corr_list, (corr_sum/folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mlp(trial, train_df, val_df, cell_features):\n",
    "    \n",
    "    layers = (30, 84, 150, 240, 258, 18, 6)\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    train_X, train_Y, val_X, val_Y = prepare_data(train_df, val_df, cell_features)\n",
    "    \n",
    "    regr = MLPRegressor(shuffle=True, early_stopping=True, learning_rate='constant', batch_size=64, activation='tanh', hidden_layer_sizes=layers, alpha=alpha)\n",
    "    regr.fit(train_X, train_Y)\n",
    "    predicted_Y = regr.predict(val_X)\n",
    "    corr = stats.pearsonr(val_Y, predicted_Y)[0]\n",
    "    if math.isnan(corr):\n",
    "        corr = 0.0\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp(dataset, ont, drug, cell_features, folds=5):\n",
    "    \n",
    "    fold_corr_list = []\n",
    "    corr_sum = 0.0\n",
    "    for i in range(1, folds+1):\n",
    "\n",
    "        all_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_train_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=(['cell', 'smiles', 'auc', 'dataset']))\n",
    "        train_df, val_df = split_train_data(all_df)\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(lambda trial: optimize_mlp(trial, train_df, val_df, cell_features), n_trials=10)\n",
    "        best_params = study.best_params\n",
    "        \n",
    "        test_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_test_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=['cell', 'smiles', 'auc', 'dataset'])\n",
    "        train_X, train_Y, test_X, test_Y = prepare_data(all_df, test_df, cell_features)\n",
    "        \n",
    "        layers = (30, 84, 150, 240, 258, 18, 6)\n",
    "        regr = MLPRegressor(shuffle=True, early_stopping=True, learning_rate='constant', batch_size=64, activation='tanh', hidden_layer_sizes=layers, alpha=best_params['alpha'])\n",
    "        regr.fit(train_X, train_Y)\n",
    "        predicted_Y = regr.predict(test_X)\n",
    "\n",
    "        corr = stats.pearsonr(test_Y, predicted_Y)[0]\n",
    "        fold_corr_list.append(corr)\n",
    "        corr_sum += corr\n",
    "\n",
    "        modeldir = \"../models/mlp/\"\n",
    "        np.savetxt(modeldir + \"predict_\" + dataset + '_' + drug + '_' + str(i) + \".txt\", predicted_Y, fmt = '%.4e')\n",
    "\n",
    "    return fold_corr_list, (corr_sum/folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_elastic_net_genie(dataset, ont, drug, gene_list, cell_map_train, cell_features_train, cell_map_test, cell_features_test, folds=5):\n",
    "    \n",
    "    for i in range(1, folds+1):\n",
    "\n",
    "        train_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_train_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=(['cell', 'smiles', 'auc', 'dataset']))\n",
    "        train_X, train_Y = prepare_data_feat(train_df, gene_list, cell_map_train, cell_features_train)\n",
    "        \n",
    "        test_df = pd.read_csv(\"../data/GENIE/GENIE_test_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=['cell', 'smiles', 'auc', 'dataset'])\n",
    "        test_X, test_Y = prepare_data_feat(test_df, gene_list, cell_map_test, cell_features_test)\n",
    "        \n",
    "        regr = ElasticNetCV(fit_intercept=False, cv=10, max_iter=3000, tol=1e-3, n_jobs=-2)\n",
    "        regr.fit(train_X, train_Y)\n",
    "        predicted_Y = regr.predict(test_X)\n",
    "        \n",
    "        modeldir = \"../models/elastic_net/\"\n",
    "        np.savetxt(modeldir + \"predict_genie_\" + dataset + '_' + drug + '_' + str(i) + \".txt\", predicted_Y, fmt = '%.4e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest_genie(dataset, ont, drug, gene_list, cell_map_train, cell_features_train, cell_map_test, cell_features_test, folds=5):\n",
    "    \n",
    "    for i in range(1, folds+1):\n",
    "\n",
    "        train_df = pd.read_csv(\"../data/training_files_av/\" + str(i) + \"_train_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=(['cell', 'smiles', 'auc', 'dataset']))\n",
    "        train_X, train_Y = prepare_data_feat(train_df, gene_list, cell_map_train, cell_features_train)\n",
    "        \n",
    "        test_df = pd.read_csv(\"../data/GENIE/GENIE_test_\" + dataset + '_' + drug + \".txt\", sep='\\t', header=None, names=['cell', 'smiles', 'auc', 'dataset'])\n",
    "        test_X, test_Y = prepare_data_feat(test_df, gene_list, cell_map_test, cell_features_test)\n",
    "        \n",
    "        regr = RandomForestRegressor(random_state=0, n_jobs=-2)\n",
    "        regr.fit(train_X, train_Y)\n",
    "        predicted_Y = regr.predict(test_X)\n",
    "        \n",
    "        modeldir = \"../models/random_forest/\"\n",
    "        np.savetxt(modeldir + \"predict_genie_\" + dataset + '_' + drug + '_' + str(i) + \".txt\", predicted_Y, fmt = '%.4e')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'av'\n",
    "ont = 'ctg'\n",
    "zscore_method = 'auc'\n",
    "\n",
    "gene_index = pd.read_csv('../data/training_files_av/gene2ind_' + ont + '_' + dataset + '.txt', sep='\\t', header=None, names=(['I', 'G']))\n",
    "gene_list = gene_index['G']\n",
    "\n",
    "cell_index = pd.read_csv('../data/training_files_av/cell2ind_' + dataset + '.txt', sep='\\t', header=None, names=(['I', 'C']))\n",
    "cell_map = dict(zip(cell_index['C'], cell_index['I']))\n",
    "\n",
    "mutations = pd.read_csv('../data/training_files_av/cell2mutation_' + ont + '_' + dataset + '.txt', header=None, names=gene_list)\n",
    "cn_deletions = pd.read_csv('../data/training_files_av/cell2cndeletion_' + ont + '_' + dataset + '.txt', header=None, names=gene_list)\n",
    "cn_amplifications = pd.read_csv('../data/training_files_av/cell2cnamplification_' + ont + '_' + dataset + '.txt', header=None, names=gene_list)\n",
    "\n",
    "#cell_features = np.concatenate([mutations, cn_deletions, cn_amplifications])\n",
    "cell_features = np.array(mutations | cn_deletions | cn_amplifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = list(pd.read_csv('../data/training_files_av/drugname_av.txt', header=None, names=['D'])['D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_df = pd.DataFrame(index=range(len(drugs)), columns=['Drug', 'Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5', 'Average'])\n",
    "\n",
    "for i, drug in enumerate(drugs):\n",
    "    \n",
    "    corr_list, avg_corr = run_elastic_net(dataset, ont, drug, cell_features)\n",
    "    print(drug, corr_list, avg_corr)\n",
    "    \n",
    "    elasticnet_df.loc[i]['Drug'] = drug\n",
    "    elasticnet_df.loc[i]['Average'] = avg_corr\n",
    "    for k in range(5):\n",
    "        elasticnet_df.loc[i]['Fold_'+str(k+1)] = corr_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticnet_df.to_csv('../models/elastic_net/corr_50.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_df = pd.DataFrame(index=range(len(drugs)), columns=['Drug', 'Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5', 'Average'])\n",
    "\n",
    "for i, drug in enumerate(drugs):\n",
    "    \n",
    "    corr_list, avg_corr = run_random_forest(dataset, ont, drug, cell_features)\n",
    "    print(drug, corr_list, avg_corr)\n",
    "    \n",
    "    randomforest_df.loc[i]['Drug'] = drug\n",
    "    randomforest_df.loc[i]['Average'] = avg_corr\n",
    "    for k in range(5):\n",
    "        randomforest_df.loc[i]['Fold_'+str(k+1)] = corr_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_df.to_csv('../models/random_forest/corr_50.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_df = pd.DataFrame(index=range(len(drugs)), columns=['Drug', 'Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5', 'Average'])\n",
    "\n",
    "for i, drug in enumerate(drugs):\n",
    "    \n",
    "    corr_list, avg_corr = run_mlp(dataset, ont, drug, cell_features)\n",
    "    print(drug, corr_list, avg_corr)\n",
    "    \n",
    "    mlp_df.loc[i]['Drug'] = drug\n",
    "    mlp_df.loc[i]['Average'] = avg_corr\n",
    "    for k in range(5):\n",
    "        mlp_df.loc[i]['Fold_'+str(k+1)] = corr_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_df.to_csv('../models/mlp/corr_50.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'av'\n",
    "ont = 'ctg'\n",
    "\n",
    "gene_index = pd.read_csv('../data/training_files_av/gene2ind_' + ont + '_' + dataset + '.txt', sep='\\t', header=None, names=(['I', 'G']))\n",
    "gene_list = gene_index['G']\n",
    "\n",
    "cell_index = pd.read_csv('../data/training_files_av/cell2ind_' + dataset + '.txt', sep='\\t', header=None, names=(['I', 'C']))\n",
    "cell_map = dict(zip(cell_index['C'], cell_index['I']))\n",
    "cell_features = pd.read_csv('../data/training_files_av/cell2mutation_' + ont + '_' + dataset + '.txt', header=None, names=gene_list)\n",
    "\n",
    "cell_index_genie = pd.read_csv('../data/GENIE/GENIE_all_cell2ind.txt', sep='\\t', header=None, names=(['I', 'C']))\n",
    "cell_map_genie = dict(zip(cell_index_genie['C'], cell_index_genie['I']))\n",
    "cell_features_genie = pd.read_csv('../data/GENIE/GENIE_cell2mutation_' + dataset + '.txt', header=None, names=gene_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = [\"Palbociclib\"]\n",
    "\n",
    "for drug in drugs:\n",
    "    run_elastic_net_genie(dataset, ont, drug, gene_list, cell_map, cell_features, cell_map_genie, cell_features_genie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in drugs:\n",
    "    run_random_forest_genie(dataset, ont, drug, gene_list, cell_map, cell_features, cell_map_genie, cell_features_genie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
